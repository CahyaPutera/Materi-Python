{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Tokenization is essentially splitting a phrase, sentence, paragraph, or an entire text document into smaller units, such as individual words or terms. Each of these smaller units are called tokens.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why is Tokenization required in NLP?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before processing a natural language, we need to identify the words that constitute a string of characters. That’s why tokenization is the most basic step to proceed with NLP (text data). This is important because the meaning of the text could easily be interpreted by analyzing the words present in the text.\n",
    "\n",
    "Let’s take an example. Consider the below string:\n",
    "\n",
    "                                                       “This is a cat.”\n",
    "\n",
    "What do you think will happen after we perform tokenization on this string? We get [‘This’, ‘is’, ‘a’, cat’].\n",
    "There are numerous uses of doing this. We can use this tokenized form to:\n",
    "Count the number of words in the text\n",
    "Count the frequency of the word, that is, the number of times a particular word is present"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Perform Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Tokenization using Python’s split() function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word Tokenization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46 µs, sys: 1e+03 ns, total: 47 µs\n",
      "Wall time: 53.2 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Founded',\n",
       " 'in',\n",
       " '2002,',\n",
       " 'SpaceX’s',\n",
       " 'mission',\n",
       " 'is',\n",
       " 'to',\n",
       " 'enable',\n",
       " 'humans',\n",
       " 'to',\n",
       " 'become',\n",
       " 'a',\n",
       " 'spacefaring',\n",
       " 'civilization.',\n",
       " 'A',\n",
       " 'multi-planet',\n",
       " 'species',\n",
       " 'by',\n",
       " 'building',\n",
       " 'a',\n",
       " 'self-sustaining',\n",
       " 'city',\n",
       " 'on',\n",
       " 'Mars.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "text = \"\"\"Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization. A multi-planet species by building a self-sustaining city on Mars.\"\"\"# Splits at space \n",
    "text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sentence Tokenization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42 µs, sys: 1 µs, total: 43 µs\n",
      "Wall time: 48.9 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization',\n",
       " 'A multi-planet species by building a self-sustaining city on Mars.']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "text = \"\"\"Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization. A multi-planet species by building a self-sustaining city on Mars.\"\"\"# Splits at space \n",
    "# Splits at '.' \n",
    "text.split('. ') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Tokenization using Regex function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42 µs, sys: 0 ns, total: 42 µs\n",
      "Wall time: 46 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Founded',\n",
       " 'in',\n",
       " '2002',\n",
       " 'SpaceX',\n",
       " 's',\n",
       " 'mission',\n",
       " 'is',\n",
       " 'to',\n",
       " 'enable',\n",
       " 'humans',\n",
       " 'to',\n",
       " 'become',\n",
       " 'a',\n",
       " 'spacefaring',\n",
       " 'civilization',\n",
       " 'A',\n",
       " 'multi',\n",
       " 'planet',\n",
       " 'species',\n",
       " 'by',\n",
       " 'building',\n",
       " 'a',\n",
       " 'self',\n",
       " 'sustaining',\n",
       " 'city',\n",
       " 'on',\n",
       " 'Mars']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "text = \"\"\"Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization. A multi-planet species by building a self-sustaining city on Mars.\"\"\"# Splits at space \n",
    "word = re.findall(\"[\\w']+\", text)\n",
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30 µs, sys: 1 µs, total: 31 µs\n",
      "Wall time: 35 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization',\n",
       " 'A multi-planet species by building a self-sustaining city on Mars.']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "sentences = re.compile('[.!?] ').split(text)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Tokenization using NLTK function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 533 µs, sys: 0 ns, total: 533 µs\n",
      "Wall time: 538 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Founded',\n",
       " 'in',\n",
       " '2002',\n",
       " ',',\n",
       " 'SpaceX',\n",
       " '’',\n",
       " 's',\n",
       " 'mission',\n",
       " 'is',\n",
       " 'to',\n",
       " 'enable',\n",
       " 'humans',\n",
       " 'to',\n",
       " 'become',\n",
       " 'a',\n",
       " 'spacefaring',\n",
       " 'civilization',\n",
       " '.',\n",
       " 'A',\n",
       " 'multi-planet',\n",
       " 'species',\n",
       " 'by',\n",
       " 'building',\n",
       " 'a',\n",
       " 'self-sustaining',\n",
       " 'city',\n",
       " 'on',\n",
       " 'Mars',\n",
       " '.']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "text = \"\"\"Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization. A multi-planet species by building a self-sustaining city on Mars.\"\"\"# Splits at space \n",
    "word_tokenize(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 194 µs, sys: 1e+03 ns, total: 195 µs\n",
      "Wall time: 199 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization.',\n",
       " 'A multi-planet species by building a self-sustaining city on Mars.']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "text = \"\"\"Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization. A multi-planet species by building a self-sustaining city on Mars.\"\"\"# Splits at space \n",
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Tokenization using regexp_tokenize function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.regexp import regexp_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 71 µs, sys: 1e+03 ns, total: 72 µs\n",
      "Wall time: 76.1 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Founded',\n",
       " 'in',\n",
       " '2002,',\n",
       " 'SpaceX’s',\n",
       " 'mission',\n",
       " 'is',\n",
       " 'to',\n",
       " 'enable',\n",
       " 'humans',\n",
       " 'to',\n",
       " 'become',\n",
       " 'a',\n",
       " 'spacefaring',\n",
       " 'civilization.',\n",
       " 'A',\n",
       " 'multi-planet',\n",
       " 'species',\n",
       " 'by',\n",
       " 'building',\n",
       " 'a',\n",
       " 'self-sustaining',\n",
       " 'city',\n",
       " 'on',\n",
       " 'Mars.']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "text = \"\"\"Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization. A multi-planet species by building a self-sustaining city on Mars.\"\"\"# Splits at space \n",
    "regexp_tokenize(text, pattern = '\\s+', gaps = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51 µs, sys: 0 ns, total: 51 µs\n",
      "Wall time: 55.1 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization',\n",
       " ' A multi-planet species by building a self-sustaining city on Mars']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "text = \"\"\"Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization. A multi-planet species by building a self-sustaining city on Mars.\"\"\"# Splits at space \n",
    "regexp_tokenize(text, pattern = '[.!?]', gaps = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
